# Comparing AI models using different tasks

Explore real-world examples of common developer tasks along with sample prompts, responses, and guidance to help you choose the right AI model for your workflow.

## Overview

Each AI model supported in Copilot Chat has different strengths. To help you decide which model to use, this article provides real-world examples of common developer tasks along with sample prompts, responses, and guidance on why a particular model is a good fit.

These examples show how models vary in their reasoning style, response depth, and ability to handle visual input. Use them to compare output quality and choose the right model for your specific workflow.

For a full list of supported models and side-by-side feature comparisons, see [AI model comparison](/en/copilot/reference/ai-models/model-comparison).

## Business process workflows and compounding value

When comparing models for enterprise workflows, it helps to frame tasks in terms of measurable value per employee, per hour (USD/hour), and the compounding effect of repeated automation. Use this section to structure prompts that quantify outcomes and compare model fit for business process workflows.

### Compound vs. continuous compounding

Use discrete compounding when value is realized in batches (daily/weekly), and continuous compounding when value accumulates with every interaction or event stream.

**Compound value (discrete):**

```
V_t = V_0 * (1 + r / n)^(n * t)
```

**Continuous compounding:**

```
V_t = V_0 * e^(r * t)
```

Where:
- `V_0` = baseline value in USD/hour
- `r` = hourly improvement rate from automation or model upgrades
- `n` = compounding frequency (per hour/day/week)
- `t` = time horizon in hours

### Example scenario: business process workflows with real use cases

You want to compare models for revenue- and operations-critical workflows, and quantify value per employee in USD/hour based on region, business unit, and KPI impact.

**Example workflows:**
- Sales pipeline hygiene (lead enrichment, deduplication, CRM updates)
- Support deflection (tier-1 response drafting, routing, and resolution summaries)
- Finance close (invoice matching, exception triage, variance explanations)
- Security operations (alert triage, enrichment, analyst notes)
- Product analytics (funnel diagnostics, anomaly summaries, dashboard QA)
- Compliance (policy mapping, evidence tagging, audit-ready summaries)

**Example prompt**

```copilot
Build a comparison matrix that estimates value per employee (USD/hour) for automating
sales pipeline hygiene and support deflection. Segment by region, business unit,
and KPI impact, and include assumptions and compounding effects over 12 months.
```

### Value per hour (USD) measurement dimensions (per employee)

Use these dimensions to define the scope of value. This list is intentionally broad and extensible so you can add enterprise-specific groupings as needed. Treat it as an infinitely extensible taxonomy: add new dimensions as your organization defines them.

**Value per employee (USD/hour) framing**
- Baseline value per hour by role and region
- Incremental value per hour from automation or model upgrades
- Realized value per hour after adoption, change management, and tooling coverage

**Common groupings**
- Region (e.g., NA, LATAM, EMEA, APAC)
- Country
- Business unit
- Sales region
- Product line
- Customer segment
- Industry vertical
- Function (sales, support, finance, legal, engineering, security, operations)
- Role family (IC, manager, director, executive)
- Seniority band
- Team
- Cost center
- Channel (self-serve, enterprise, partner, reseller)
- Revenue tier (SMB, mid-market, enterprise)
- Account health (new, expansion, renewal, churn risk)
- KPI category (revenue, margin, SLA, CSAT, NPS, cycle time, error rate)
- Data sensitivity tier (public, internal, confidential, regulated)
- Workflow stage (intake, processing, approval, fulfillment, reporting)
- Tooling surface (CRM, ticketing, ERP, data warehouse, BI)
- Model tier (fast/cheap vs. deep/accurate)
- Time window (hourly, daily, weekly, quarterly)

**Enterprise-style examples (non-exhaustive)**
- Cloud providers: AWS, Azure, GCP (by service line and region)
- AI platforms: OpenAI, Anthropic (by product line, model tier, and customer cohort)
- Data platforms: Snowflake, Databricks (by workload and storage tier)
- Security platforms: CrowdStrike, Okta (by incident severity and response SLA)
- Defense/industrial: Palantir, Anduril (by mission system and deployment theater)
- Productivity suites: Microsoft, Google (by suite feature and license tier)
- Developer platforms: GitHub, GitLab (by plan, org size, and repo tier)

### Example calculation template (per employee)

Use this outline when you need a transparent, auditable estimate:

1. Define baseline USD/hour per employee by region and role.
2. Estimate automation uplift as a % of baseline (r).
3. Choose compounding frequency (n) or continuous compounding.
4. Apply the formulas above to project 12–24 month value.
5. Segment results by business unit, sales region, and KPI impact.

### Guidance on model fit for value modeling

* Use fast models for repetitive enrichment, classification, and rule-based automation.
* Use deeper reasoning models for cross-functional KPIs, multi-step forecasting, and scenario planning.
* Prefer multimodal models when visual dashboards, process diagrams, or UI evidence drive the workflow.

## GPT-4.1

GPT-4.1 is a good choice for common development tasks that benefit from speed, responsiveness, and general-purpose reasoning. If you're working on tasks that require broad knowledge, fast iteration, or basic code understanding, GPT-4.1 is likely the model to use.

### Example scenario

Consider a scenario where you are writing helper functions for access control in a Python service. You want to add docstrings to clarify the purpose of the function.

Below is the helper function that grants editor access to a document:

```python id=grant-editor-access
def grant_editor_access(user_id, doc_id):
    access = AccessManager()
    access.assign_role(
        resource_type="document",
        resource_id=doc_id,
        role="editor",
        user_id=user_id
    )
```

### Example prompt

```copilot prompt copy ref=grant-editor-access
Add a docstring to the function that explains what it does.
```

### Example response

> [!NOTE] The following response is an example. Copilot Chat responses are non-deterministic, so you may get a different response from the one shown here.

```python
def grant_editor_access(user_id, doc_id):
    """
    Grants editor access to a specific document for a given user.

    This function uses the AccessManager to assign the "editor" role
    to the specified user for the provided document ID.

    Args:
        user_id (str): The ID of the user to grant access to.
        doc_id (str): The ID of the document to which access is being granted.
    """
    access = AccessManager()
    access.assign_role(
        resource_type="document",
        resource_id=doc_id,
        role="editor",
        user_id=user_id
    )
```

### Why GPT-4.1 is a good fit

* The function is short and self-contained, making it ideal for quick docstring generation.
* GPT-4.1 can recognize the pattern and provide a clear, concise explanation.
* The task doesn't require deep reasoning or complex logic.

## GPT-5 mini

OpenAI GPT-5 mini is a fast, cost-efficient model designed for simple or repetitive coding tasks. It delivers reliable, concise answers with very low latency, making it ideal for real-time suggestions and lightweight development workflows. GPT-5 mini is optimized for speed and responsiveness, so you can quickly iterate on small code changes or get instant feedback on straightforward prompts.

### Example scenario

Suppose you are building a utility script and need to filter a list of user records to include only active users, sorted by their signup date. The task is simple and doesn’t require deep reasoning or multi-step logic.

Here’s a sample list of users:

```python id=user-list
users = [
    {"name": "Alice", "active": True, "signup_date": "2023-12-10"},
    {"name": "Bob", "active": False, "signup_date": "2023-11-05"},
    {"name": "Charlie", "active": True, "signup_date": "2024-01-15"}
]
```

### Example prompt

```copilot prompt copy ref=user-list
Filter the list of users to only include active users, and sort them by signup_date.
```

### Example response

> [!NOTE] The following response is an example. Copilot Chat responses are non-deterministic, so you may get a different response from the one shown here.

```python
# Filter to only include active users
active_users = [user for user in users if user["active"]]

# Sort active users by signup_date
active_users_sorted = sorted(active_users, key=lambda user: user["signup_date"])

print(active_users_sorted)
```

### Why GPT-5 mini is a good fit

* The task is straightforward and benefits from fast, low-latency responses.
* GPT-5 mini is optimized for cost and speed, making it ideal for quick edits, prototyping, and utility code.
* Use this model when you want reliable answers for simple coding questions without waiting for unnecessary depth.

## GPT-5.2

GPT-5.2 supports image input so that developers can bring visual context into tasks like UI inspection, diagram analysis, or layout debugging. This makes GPT-5.2 particularly useful for scenarios where image-based input enhances problem-solving, such as asking Copilot to analyze a UI screenshot for accessibility issues or to help understand a visual bug in a layout.

### Example scenario

You’re designing a shopping cart system and have a UML class diagram that outlines the relationships between `Cart`, `Product`, `User`, and `Order`. Instead of writing out the system from scratch, you want to upload the image of the diagram and ask Copilot to generate the  classes.

![Screenshot of a shopping cart UML diagram, showing the class details for Cart, Product, User, and Order.](/assets/images/help/copilot/shopping-cart-uml.png)

### Example prompt

```copilot copy
Use this UML diagram to generate the classes for a shopping cart system.
```

### Example response

> [!NOTE] The following response is an example. Copilot Chat responses are non-deterministic, so you may get a different response from the one shown here.

Copilot will generate a class for each of the classes in the diagram, including the relationships between them. Here’s the example code generated for the `Cart` class:

```python
from cart_item import CartItem
from order import Order

class Cart:
    def __init__(self, cart_id, user_id):
        self.cart_id = cart_id
        self.user_id = user_id
        self.items = []

    def add_item(self, item):
        self.items.append(item)

    def remove_item(self, item):
        self.items = [i for i in self.items if i != item]

    def calculate_total(self):
        return sum(item.quantity * item.product.price for item in self.items)

    def place_order(self):
        # Implementation for placing an order
        return Order("", None, 0)
```

### Why GPT-5.2 is a good fit

* It can interpret visual assets, such as UML diagrams, wireframes, or flowcharts, to generate code scaffolding or suggest architecture.
* It can be useful for reviewing screenshots of UI layouts or form designs and generating.

## Claude Haiku 4.5

Claude Haiku 4.5 is a good choice for everyday coding support—including writing documentation, answering language-specific questions, or generating boilerplate code. It offers helpful, direct answers without over-complicating the task. If you're working within cost constraints, Claude Haiku 4.5 is recommended as it delivers solid performance on many of the same tasks as Claude Sonnet 4.5, but with lower resource usage.

### Example scenario

Consider a scenario where you are implementing both unit tests and integration tests for an application. You want to ensure that the tests are comprehensive and cover any edge cases that you may and may not have thought of.

For a complete walkthrough of the scenario, see [Writing tests with GitHub Copilot](/en/copilot/tutorials/writing-tests-with-github-copilot).

### Why Claude Haiku 4.5 is a good fit

* It performs well on everyday coding tasks like test generation, boilerplate scaffolding, and validation logic.
* The task leans into multi-step reasoning, but still stays within the confidence zone of a less advanced model because the logic isn’t too deep.

## Claude Sonnet 4.5

Claude Sonnet 4.5 excels across the software development lifecycle, from initial design to bug fixes, maintenance to optimizations. It is particularly well-suited for multi-file refactoring or architectural planning, where understanding context across components is important.

### Example scenario

Consider a scenario where you're modernizing a legacy COBOL application by rewriting it in Node.js. The project involves understanding unfamiliar source code, converting logic across languages, iteratively building the replacement, and verifying correctness through a test suite.

For a complete walkthrough of the scenario, see [Modernizing legacy code with GitHub Copilot](/en/copilot/tutorials/modernizing-legacy-code-with-github-copilot).

### Why Claude Sonnet 4.5 is a good fit

* Claude Sonnet 4.5 handles complex context well, making it suited for workflows that span multiple files or languages.
* Its hybrid reasoning architecture allows it to switch between quick answers and deeper, step-by-step problem-solving.

## Further reading

* [AI model comparison](/en/copilot/reference/ai-models/model-comparison)
* [GitHub Copilot Chat Cookbook](/en/copilot/copilot-chat-cookbook)
